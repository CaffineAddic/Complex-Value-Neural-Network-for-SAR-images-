{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 21:20:16.378010: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-17 21:20:17.296065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from cvnn import layers\n",
    "import numpy as np\n",
    "import timeit\n",
    "import datetime\n",
    "from pdb import set_trace\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly\n",
    "    PLOTLY = True\n",
    "except ModuleNotFoundError:\n",
    "    PLOTLY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tf.enable_v2_behavior()\n",
    "# tfds.disable_progress_bar()\n",
    "\n",
    "\n",
    "PLOTLY_CONFIG = {\n",
    "    'scrollZoom': True,\n",
    "    'editable': True\n",
    "}\n",
    "\n",
    "\n",
    "def cast_to_complex(image, label):\n",
    "    return tf.cast(image, tf.complex64), label\n",
    "\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'mnist',\n",
    "        split=['train', 'test'],\n",
    "        shuffle_files=False,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "\n",
    "    ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    # ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds_train, ds_test\n",
    "\n",
    "\n",
    "def keras_fit(ds_train, ds_test, verbose=True, init1='glorot_uniform', init2='glorot_uniform', train_bias=True):\n",
    "    tf.random.set_seed(24)\n",
    "    # https://www.tensorflow.org/datasets/keras_example\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28, 1), dtype=np.float32),\n",
    "      tf.keras.layers.Dense(128, activation='relu', kernel_initializer=init1, dtype=np.float32, use_bias=train_bias),\n",
    "      tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=init2, dtype=np.float32, use_bias=train_bias)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    weigths = model.get_weights()\n",
    "    with tf.GradientTape() as tape:\n",
    "        # for elem, label in iter(ds_train):\n",
    "        elem, label = next(iter(ds_test))\n",
    "        loss = model.compiled_loss(y_true=label, y_pred=model(elem))    # calculate loss\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)        # back-propagation\n",
    "    logs = {\n",
    "        'weights': weigths,\n",
    "        'loss': loss,\n",
    "        'gradients': gradients\n",
    "    }\n",
    "    start = timeit.default_timer()\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        epochs=6,\n",
    "        validation_data=ds_test,\n",
    "        verbose=verbose, shuffle=False\n",
    "    )\n",
    "    stop = timeit.default_timer()\n",
    "    return history, stop - start, logs\n",
    "\n",
    "\n",
    "def own_complex_fit(ds_train, ds_test, verbose=True, init1='glorot_uniform', init2='glorot_uniform'):\n",
    "    tf.random.set_seed(24)\n",
    "    model = tf.keras.models.Sequential([\n",
    "        layers.ComplexFlatten(input_shape=(28, 28, 1), dtype=np.complex64),\n",
    "        layers.ComplexDense(128, activation='cart_relu', dtype=np.complex64, kernel_initializer=init1,\n",
    "                            use_bias=False, init_technique='zero_imag'),\n",
    "        layers.ComplexDense(10, activation='cast_to_real', dtype=np.complex64, kernel_initializer=init2,\n",
    "                            use_bias=False, init_technique='zero_imag'),\n",
    "        tf.keras.layers.Activation('softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    # ds_train = ds_train.map(cast_to_complex)\n",
    "    # ds_test = ds_test.map(cast_to_complex)\n",
    "    weigths = model.get_weights()\n",
    "    with tf.GradientTape() as tape:\n",
    "        # for elem, label in iter(ds_train):\n",
    "        elem, label = next(iter(ds_test))\n",
    "        loss = model.compiled_loss(y_true=label, y_pred=model(elem))  # calculate loss\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)  # back-propagation\n",
    "    logs = {\n",
    "        'weights': weigths,\n",
    "        'loss': loss,\n",
    "        'gradients': gradients\n",
    "    }\n",
    "    start = timeit.default_timer()\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        epochs=6,\n",
    "        validation_data=ds_test,\n",
    "        verbose=verbose, shuffle=False\n",
    "    )\n",
    "    stop = timeit.default_timer()\n",
    "    return history, stop - start, logs\n",
    "\n",
    "\n",
    "def own_fit(ds_train, ds_test, verbose=True, init1='glorot_uniform', init2='glorot_uniform'):\n",
    "    tf.random.set_seed(24)\n",
    "    model = tf.keras.models.Sequential([\n",
    "        layers.ComplexFlatten(input_shape=(28, 28, 1), dtype=np.float32),\n",
    "        layers.ComplexDense(128, activation='cart_relu', dtype=np.float32, kernel_initializer=init1),\n",
    "        layers.ComplexDense(10, activation='softmax_real_with_abs', dtype=np.float32, kernel_initializer=init2)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    weigths = model.get_weights()\n",
    "    with tf.GradientTape() as tape:\n",
    "        # for elem, label in iter(ds_train):\n",
    "        elem, label = next(iter(ds_test))\n",
    "        loss = model.compiled_loss(y_true=label, y_pred=model(elem))    # calculate loss\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)        # back-propagation\n",
    "    logs = {\n",
    "        'weights': weigths,\n",
    "        'loss': loss,\n",
    "        'gradients': gradients\n",
    "    }\n",
    "    start = timeit.default_timer()\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        epochs=6,\n",
    "        validation_data=ds_test,\n",
    "        verbose=verbose, shuffle=False\n",
    "    )\n",
    "    stop = timeit.default_timer()\n",
    "    return history, stop - start, logs\n",
    "\n",
    "\n",
    "def test_mnist():\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    # for device in visible_devices:\n",
    "    #     assert device.device_type != 'GPU', \"Using GPU not good for debugging\"\n",
    "    ds_train, ds_test = get_dataset()\n",
    "    # Don't use bias becase complex model gets a complex bias with imag not zero.\n",
    "    keras_hist, keras_time, keras_logs = keras_fit(ds_train, ds_test, train_bias=False)\n",
    "    keras_weigths = keras_logs['weights']\n",
    "    own_cvnn_hist, own_cvnn_time, own_cvnn_logs = own_complex_fit(ds_train, ds_test)\n",
    "    own_cvnn_weigths = own_cvnn_logs['weights']\n",
    "    assert np.all([np.all(k_w == o_w) for k_w, o_w in zip(keras_weigths, own_cvnn_weigths[::2])])\n",
    "    assert np.all([np.all(o_w == 0) for o_w in own_cvnn_weigths[1::2]])\n",
    "    assert own_cvnn_logs['loss'] == keras_logs['loss']\n",
    "    assert np.allclose(own_cvnn_logs['gradients'][2], keras_logs['gradients'][1])\n",
    "    # for k, o in zip(keras_hist.history.values(), own_cvnn_hist.history.values()):\n",
    "    #     assert np.allclose(k, o), f\"\\n{keras_hist.history}\\n !=\\n{own_cvnn_hist.history}\"\n",
    "    # DO AGAIN TO USE BIAS\n",
    "    keras_hist, keras_time, keras_logs = keras_fit(ds_train, ds_test)\n",
    "    keras_weigths = keras_logs['weights']\n",
    "    own_hist, own_time, own_logs = own_fit(ds_train, ds_test)\n",
    "    own_weigths = own_logs['weights']\n",
    "    assert [np.all(k_w == o_w) for k_w, o_w in zip(keras_weigths, own_weigths)]\n",
    "    assert keras_hist.history == own_hist.history, f\"\\n{keras_hist.history}\\n !=\\n{own_hist.history}\"\n",
    "    assert own_logs['loss'] == keras_logs['loss']\n",
    "    # for k, k2, o in zip(keras_hist.history.values(), keras2_hist.history.values(), own_hist.history.values()):\n",
    "    #     if np.all(np.array(k) == np.array(k2)):\n",
    "    #         assert np.all(np.array(k) == np.array(o)), f\"\\n{keras_hist.history}\\n !=\\n{own_hist.history}\"\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from importlib import reload\n",
    "    import os\n",
    "    import tensorflow\n",
    "    reload(tensorflow)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    test_mnist()\n",
    "    # test_mnist_montecarlo()\n",
    "    # ds_train, ds_test = get_dataset()\n",
    "    # keras_fit(ds_train, ds_test, train_bias=False)\n",
    "    # own_fit(ds_train, ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 21:20:26.227785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-17 21:20:26.262002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-17 21:20:26.262347: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
