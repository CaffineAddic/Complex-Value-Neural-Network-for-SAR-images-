{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, Optional, Any\n",
    "from cvnn.losses import ComplexAverageCrossEntropy, ComplexWeightedAverageCrossEntropy\n",
    "from cvnn.metrics import ComplexCategoricalAccuracy, ComplexAverageAccuracy, ComplexPrecision, ComplexRecall\n",
    "from cvnn.layers import complex_input, ComplexConv2D, ComplexDropout, \\\n",
    "    ComplexMaxPooling2DWithArgmax, ComplexUnPooling2D, ComplexInput, ComplexBatchNormalization, ComplexDense, \\\n",
    "    ComplexUpSampling2D, ComplexConv2DTranspose, ComplexAvgPooling2D, ComplexPolarAvgPooling2D, ComplexMaxPooling2D\n",
    "from cvnn.activations import cart_softmax, cart_relu\n",
    "from cvnn.initializers import ComplexHeNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.layers import Concatenate, Add, Activation, Input\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Conv2DTranspose, BatchNormalization, MaxPooling2D, \\\n",
    "    UpSampling2D, AvgPool2D\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.metrics import Recall, Precision, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'padding': 'same',\n",
    "    'consecutive_conv_layers': 0,\n",
    "    'kernel_shape': (3, 3),\n",
    "    'block6_kernel_shape': (1, 1),\n",
    "    'max_pool_kernel': (2, 2),\n",
    "    'concat': Add,\n",
    "    'upsampling_layer': ComplexUnPooling2D,\n",
    "    'stride': 2,\n",
    "    'pooling': ComplexMaxPooling2DWithArgmax,\n",
    "    'activation': cart_relu,\n",
    "    'kernels': [12, 24, 48, 96, 192],\n",
    "    'output_function': cart_softmax,\n",
    "    'init': ComplexHeNormal,\n",
    "    'optimizer': Adam,\n",
    "    'learning_rate': 0.0001,\n",
    "    'depth': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT_DEFAULT = {\n",
    "    \"downsampling\": None,\n",
    "    \"bottle_neck\": None,\n",
    "    \"upsampling\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_HEIGHT = None  # 128\n",
    "IMG_WIDTH = None  # 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_downsampling_block(input_to_block, num: int, dtype=np.complex64, dropout: Optional[bool] = False):\n",
    "    conv = ComplexConv2D(hyper_params['kernels'][:hyper_params['depth']][num], hyper_params['kernel_shape'],\n",
    "                         activation='linear', padding=hyper_params['padding'],\n",
    "                         kernel_initializer=hyper_params['init'](), dtype=dtype)(input_to_block)\n",
    "    for _ in range(hyper_params['consecutive_conv_layers']):\n",
    "        conv = ComplexConv2D(hyper_params['kernels'][:hyper_params['depth']][num], hyper_params['kernel_shape'],\n",
    "                             activation='linear', padding=hyper_params['padding'],\n",
    "                             kernel_initializer=hyper_params['init'](), dtype=dtype)(conv)\n",
    "    conv = ComplexBatchNormalization(dtype=dtype)(conv)\n",
    "    conv = Activation(hyper_params['activation'])(conv)\n",
    "    if hyper_params['pooling'] == ComplexMaxPooling2DWithArgmax:\n",
    "        pool, pool_argmax = ComplexMaxPooling2DWithArgmax(hyper_params['max_pool_kernel'],\n",
    "                                                          strides=hyper_params['stride'])(conv)\n",
    "    elif hyper_params['pooling'] == ComplexAvgPooling2D:\n",
    "        pool = ComplexAvgPooling2D(hyper_params['max_pool_kernel'], strides=hyper_params['stride'])(conv)\n",
    "        pool_argmax = None\n",
    "    elif hyper_params['pooling'] == ComplexPolarAvgPooling2D:\n",
    "        pool = ComplexPolarAvgPooling2D(hyper_params['max_pool_kernel'], strides=hyper_params['stride'])(conv)\n",
    "        pool_argmax = None\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown pooling {hyper_params['pooling']}\")\n",
    "    if dropout:\n",
    "        pool = ComplexDropout(rate=dropout, dtype=dtype)(pool)\n",
    "    return pool, pool_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_upsampling_block(input_to_block, pool_argmax, kernels, num: int, activation,\n",
    "                          dropout: Optional[bool] = False, dtype=np.complex64):\n",
    "    if hyper_params['upsampling_layer'] == ComplexUnPooling2D:\n",
    "        unpool = ComplexUnPooling2D(upsampling_factor=2)([input_to_block, pool_argmax])\n",
    "    elif hyper_params['upsampling_layer'] == ComplexUpSampling2D:\n",
    "        unpool = ComplexUpSampling2D(size=2)(input_to_block)\n",
    "    elif hyper_params['upsampling_layer'] == ComplexConv2DTranspose:\n",
    "        unpool = ComplexConv2DTranspose(filters=num, kernel_size=3, strides=(2, 2), padding='same',\n",
    "                                        dilation_rate=(1, 1))(input_to_block)\n",
    "    else:\n",
    "        raise ValueError(f\"Upsampling method {hyper_params['upsampling_layer'].name} not supported\")\n",
    "    conv = ComplexConv2D(kernels, hyper_params['kernel_shape'],\n",
    "                         activation='linear', padding=hyper_params['padding'],\n",
    "                         kernel_initializer=hyper_params['init'](), dtype=dtype)(unpool)\n",
    "    for _ in range(hyper_params['consecutive_conv_layers']):\n",
    "        conv = ComplexConv2D(kernels, hyper_params['kernel_shape'],\n",
    "                             activation='linear', padding=hyper_params['padding'],\n",
    "                             kernel_initializer=hyper_params['init'](), dtype=dtype)(conv)\n",
    "    conv = ComplexBatchNormalization(dtype=dtype)(conv)\n",
    "    conv = Activation(activation)(conv)\n",
    "    if dropout:\n",
    "        conv = ComplexDropout(rate=dropout, dtype=dtype)(conv)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_my_model(in1, get_downsampling_block, get_upsampling_block, dtype=np.complex64, name=\"my_own_model\",\n",
    "                  dropout_dict=None, num_classes=4, weights=None):\n",
    "    # Downsampling\n",
    "    if dropout_dict is None:\n",
    "        dropout_dict = DROPOUT_DEFAULT\n",
    "\n",
    "    pool = in1\n",
    "    pools = []\n",
    "    argmax_pools = []\n",
    "    for index in range(len(hyper_params['kernels'][:hyper_params['depth']])):\n",
    "        pool, pool_argmax = get_downsampling_block(pool, index, dtype=dtype, dropout=dropout_dict[\"downsampling\"])\n",
    "        pools.append(pool)\n",
    "        argmax_pools.append(pool_argmax)\n",
    "\n",
    "    # Bottleneck\n",
    "    index = -1\n",
    "    conv = ComplexConv2D(hyper_params['kernels'][:hyper_params['depth']][index], (1, 1),\n",
    "                         activation=hyper_params['activation'], padding=hyper_params['padding'],\n",
    "                         dtype=dtype)(pools.pop())\n",
    "    if dropout_dict[\"bottle_neck\"] is not None:\n",
    "        conv = ComplexDropout(rate=dropout_dict[\"bottle_neck\"], dtype=dtype)(conv)\n",
    "\n",
    "    # Upsampling\n",
    "    while pools:\n",
    "        index -= 1\n",
    "        pool = pools.pop()\n",
    "        pool_argmax = argmax_pools.pop()\n",
    "        conv = get_upsampling_block(conv, pool_argmax, hyper_params['kernels'][:hyper_params['depth']][index], num=4,\n",
    "                                    activation=hyper_params['activation'],\n",
    "                                    dropout=dropout_dict[\"upsampling\"], dtype=dtype)\n",
    "        if hyper_params['concat'] == Concatenate:\n",
    "            conv = Concatenate()([conv, pool])\n",
    "        elif hyper_params['concat'] == Add:\n",
    "            conv = Add()([conv, pool])\n",
    "        else:\n",
    "            raise KeyError(f\"Concatenation {hyper_params['concat']} not known\")\n",
    "    out = get_upsampling_block(conv, argmax_pools.pop(), activation=hyper_params['output_function'], dropout=False,\n",
    "                               num=0, kernels=num_classes, dtype=dtype)\n",
    "\n",
    "    if weights is not None:\n",
    "        loss = ComplexWeightedAverageCrossEntropy(weights=weights)\n",
    "    else:\n",
    "        loss = ComplexAverageCrossEntropy()\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[out], name=name)\n",
    "    model.compile(optimizer=hyper_params['optimizer'](learning_rate=hyper_params['learning_rate']), loss=loss,\n",
    "                  metrics=[ComplexCategoricalAccuracy(name='accuracy'),\n",
    "                           ComplexAverageAccuracy(name='average_accuracy'),\n",
    "                           ComplexPrecision(name='precision'),\n",
    "                           ComplexRecall(name='recall')\n",
    "                           ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_unet_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=4, dtype=np.complex64,\n",
    "                      tensorflow: bool = False,\n",
    "                      name=\"my_model\", dropout_dict=None, weights=None, hyper_dict: Optional[Dict] = None):\n",
    "    if hyper_dict is not None:\n",
    "        for key, value in hyper_dict.items():\n",
    "            if key in hyper_params.keys():\n",
    "                hyper_params[key] = value\n",
    "            else:\n",
    "                print(f\"WARGNING: parameter {key} is not used\")\n",
    "    if dropout_dict is None:\n",
    "        dropout_dict = DROPOUT_DEFAULT\n",
    "    if not tensorflow:\n",
    "        in1 = complex_input(shape=input_shape, dtype=dtype)\n",
    "        return _get_my_model(in1, _get_downsampling_block, _get_upsampling_block, dtype=dtype, name=name,\n",
    "                             dropout_dict=dropout_dict, num_classes=num_classes, weights=weights)\n",
    "    else:\n",
    "        in1 = Input(shape=input_shape)\n",
    "        return _get_my_model_with_tf(in1, _tf_get_downsampling_block, _get_tf_upsampling_block, name=\"tf_\" + name,\n",
    "                                     dropout_dict=dropout_dict, num_classes=num_classes, weights=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
